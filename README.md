# LLM-based Counterfactual Explanations for Models of Code

This repository contains the code for my bachelor thesis titled "LLM-based Counterfactual Explanations for Models of Code". The project explores the use of large language models to generate counterfactual explanations for models predicting source code properties. Counterfactual explanations are minimal changes to the input that flip the prediction of a classifier.

## Requirements

Have a look at the requirements.txt file.

## Usage

Main.py includes a few examples demonstrating how to setup experiments. An OpenAI API key is required.
